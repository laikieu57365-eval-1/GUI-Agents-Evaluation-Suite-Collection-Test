# GUI Agents Evaluation Suite Collection

This repository collects information about HuggingFace's GUI Agents Evaluation Suite, focusing on desktop environment-related Grounding benchmarks.

## Desktop Environment-Related Grounding Benchmarks

- AgentNet: dataset:xlangai/AgentNet
- AGUVIS-stage1: dataset:xlangai/aguvis-stage1
- AGUVIS-stage2: dataset:smolagents/aguvis-stage-2
- UGround-V1-Data: dataset:osunlp/UGround-V1-Data

## About

These benchmarks are designed to evaluate GUI agents' performance on desktop environments, testing their ability to understand and interact with graphical user interfaces, handle grounding tasks, and perform computer use tasks effectively.

The evaluation suite focuses on assessing agents' capabilities in:
- Visual grounding of UI elements
- Understanding user interface layouts
- Performing computer use tasks
- Interacting with desktop environments
- Following instructions in GUI contexts

## Related Research

These benchmarks are associated with research papers and models that advance the field of GUI agents and computer use agents.

## Credits

This repository is based on HuggingFace's GUI Agents evaluation suite and desktop environment-related Grounding benchmarks.