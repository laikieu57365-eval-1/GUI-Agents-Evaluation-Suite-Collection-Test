# GUI-Agents-Evaluation-Suite-Collection-Test

A collection of information about the HuggingFace GUI Agents Evaluation Suite.

## Desktop Environment Grounding Benchmarks

This section lists all Grounding/Perception benchmarks from HuggingFace's ScreenSuite evaluation suite.

- ScreenSpot: https://huggingface.co/datasets/rootsautomation/ScreenSpot
- ScreenSpot v2: https://huggingface.co/datasets/HongxinLi/ScreenSpot_v2
- ScreenSpot-Pro: https://huggingface.co/datasets/HongxinLi/ScreenSpot-Pro
- Visual-WebBench: https://huggingface.co/datasets/visualwebbench/VisualWebBench
- WebSRC: https://huggingface.co/datasets/X-LANCE/WebSRC_v1.0
- ScreenQA-short: https://huggingface.co/datasets/rootsautomation/RICO-ScreenQA-Short
- ScreenQA-complex: https://huggingface.co/datasets/rootsautomation/RICO-ScreenQA-Complex
- Showdown-Clicks: https://huggingface.co/datasets/generalagents/showdown-clicks

## About ScreenSuite

HuggingFace has created ScreenSuite - the most comprehensive benchmarking suite for GUI Agents!

ScreenSuite is HuggingFace's flagship evaluation framework designed to comprehensively benchmark GUI agents across various environments and tasks, including:

- Grounding/Perception Benchmarks
- Single Step - Offline Agent Benchmarks
- Multi-step - Online Agent Benchmarks

### Official Resources:

- **GitHub Repository**: [huggingface/screensuite](https://github.com/huggingface/screensuite)
